{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gendered-pronoun-resolution', 'gap-coreference']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-18 11:43:31--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c07::80\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 407727028 (389M) [application/zip]\r\n",
      "Saving to: ‘uncased_L-12_H-768_A-12.zip’\r\n",
      "\r\n",
      "uncased_L-12_H-768_ 100%[===================>] 388.84M   139MB/s    in 2.8s    \r\n",
      "\r\n",
      "2019-03-18 11:43:34 (139 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\r\n",
      "\r\n",
      "bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\r\n",
      "bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "!ls 'uncased_L-12_H-768_A-12'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "e265e7becd34d793d13009f851a4fc7c6f7f95fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-18 11:43:43--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 37922 (37K) [text/plain]\r\n",
      "Saving to: ‘modeling.py’\r\n",
      "\r\n",
      "modeling.py         100%[===================>]  37.03K  --.-KB/s    in 0.007s  \r\n",
      "\r\n",
      "2019-03-18 11:43:43 (4.91 MB/s) - ‘modeling.py’ saved [37922/37922]\r\n",
      "\r\n",
      "--2019-03-18 11:43:44--  https://raw.githubusercontent.com/google-research/bert/master/extract_features.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13898 (14K) [text/plain]\r\n",
      "Saving to: ‘extract_features.py’\r\n",
      "\r\n",
      "extract_features.py 100%[===================>]  13.57K  --.-KB/s    in 0.007s  \r\n",
      "\r\n",
      "2019-03-18 11:43:44 (1.96 MB/s) - ‘extract_features.py’ saved [13898/13898]\r\n",
      "\r\n",
      "--2019-03-18 11:43:44--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 12257 (12K) [text/plain]\r\n",
      "Saving to: ‘tokenization.py’\r\n",
      "\r\n",
      "tokenization.py     100%[===================>]  11.97K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2019-03-18 11:43:44 (141 MB/s) - ‘tokenization.py’ saved [12257/12257]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n",
    "!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "440d7107d50a014003a2c53485554dc693f81982"
   },
   "outputs": [],
   "source": [
    "import modeling\n",
    "import extract_features\n",
    "import tokenization\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6a15e5f4c32659d3408dee927035725ae0135a39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Pronoun-offset</th>\n",
       "      <th>A</th>\n",
       "      <th>A-offset</th>\n",
       "      <th>A-coref</th>\n",
       "      <th>B</th>\n",
       "      <th>B-offset</th>\n",
       "      <th>B-coref</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>Upon their acceptance into the Kontinental Hoc...</td>\n",
       "      <td>His</td>\n",
       "      <td>383</td>\n",
       "      <td>Bob Suter</td>\n",
       "      <td>352</td>\n",
       "      <td>False</td>\n",
       "      <td>Dehner</td>\n",
       "      <td>366</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Jeremy_Dehner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>Between the years 1979-1981, River won four lo...</td>\n",
       "      <td>him</td>\n",
       "      <td>430</td>\n",
       "      <td>Alonso</td>\n",
       "      <td>353</td>\n",
       "      <td>True</td>\n",
       "      <td>Alfredo Di St*fano</td>\n",
       "      <td>390</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Norberto_Alonso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>Though his emigration from the country has aff...</td>\n",
       "      <td>He</td>\n",
       "      <td>312</td>\n",
       "      <td>Ali Aladhadh</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>Saddam</td>\n",
       "      <td>295</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Aladhadh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test-4</td>\n",
       "      <td>At the trial, Pisciotta said: ``Those who have...</td>\n",
       "      <td>his</td>\n",
       "      <td>526</td>\n",
       "      <td>Alliata</td>\n",
       "      <td>377</td>\n",
       "      <td>False</td>\n",
       "      <td>Pisciotta</td>\n",
       "      <td>536</td>\n",
       "      <td>True</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Gaspare_Pisciotta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-5</td>\n",
       "      <td>It is about a pair of United States Navy shore...</td>\n",
       "      <td>his</td>\n",
       "      <td>406</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>421</td>\n",
       "      <td>True</td>\n",
       "      <td>Rock Reilly</td>\n",
       "      <td>559</td>\n",
       "      <td>False</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Chasers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                       ...                                                                   URL\n",
       "0  test-1                       ...                            http://en.wikipedia.org/wiki/Jeremy_Dehner\n",
       "1  test-2                       ...                          http://en.wikipedia.org/wiki/Norberto_Alonso\n",
       "2  test-3                       ...                                 http://en.wikipedia.org/wiki/Aladhadh\n",
       "3  test-4                       ...                        http://en.wikipedia.org/wiki/Gaspare_Pisciotta\n",
       "4  test-5                       ...                                  http://en.wikipedia.org/wiki/Chasers\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df  = pd.read_table('../input/gap-coreference/gap-development.tsv')\n",
    "train_df = pd.read_table('../input/gap-coreference/gap-test.tsv')\n",
    "val_df   = pd.read_table('../input/gap-coreference/gap-validation.tsv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "128bf9ecc2123276f55c58cc7f49ed3e2c9eb30b"
   },
   "outputs": [],
   "source": [
    "def count_char(text, offset):   \n",
    "    count = 0\n",
    "    for pos in range(offset):\n",
    "        if text[pos] != \" \": count +=1\n",
    "    return count\n",
    "\n",
    "def candidate_length(candidate):\n",
    "    count = 0\n",
    "    for i in range(len(candidate)):\n",
    "        if candidate[i] !=  \" \": count += 1\n",
    "    return count\n",
    "\n",
    "def count_token_length_special(token):\n",
    "    count = 0\n",
    "    special_token = [\"#\", \" \"]\n",
    "    for i in range(len(token)):\n",
    "        if token[i] not in special_token: count+=1\n",
    "    return count\n",
    "\n",
    "def embed_by_bert(df):\n",
    "    \n",
    "    text = df['Text']\n",
    "    text.to_csv('input.txt', index=False, header=False)\n",
    "    os.system(\"python3 extract_features.py \\\n",
    "               --input_file=input.txt \\\n",
    "               --output_file=output.jsonl \\\n",
    "               --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n",
    "               --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n",
    "               --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
    "               --layers=-1 \\\n",
    "               --max_seq_length=256 \\\n",
    "               --batch_size=8\")\n",
    "    \n",
    "    bert_output = pd.read_json(\"output.jsonl\", lines = True)\n",
    "    bert_output.head()\n",
    "    \n",
    "    os.system(\"rm input.txt\")\n",
    "    os.system(\"rm output.jsonl\")\n",
    "    \n",
    "    index = df.index\n",
    "    columns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n",
    "    emb = pd.DataFrame(index = index, columns = columns)\n",
    "    emb.index.name = \"ID\"\n",
    "    \n",
    "    for i in tqdm(range(len(text))):\n",
    "        \n",
    "        features = bert_output.loc[i, \"features\"]\n",
    "        P_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'Pronoun-offset'])\n",
    "        A_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'A-offset'])\n",
    "        B_char_start = count_char(df.loc[i, 'Text'], df.loc[i, 'B-offset'])\n",
    "        A_length = candidate_length(df.loc[i, 'A'])\n",
    "        B_length = candidate_length(df.loc[i, 'B'])\n",
    "        \n",
    "        emb_A = np.zeros(768)\n",
    "        emb_B = np.zeros(768)\n",
    "        emb_P = np.zeros(768)\n",
    "        \n",
    "        char_count = 0\n",
    "        cnt_A, cnt_B = 0, 0\n",
    "        \n",
    "        for j in range(2, len(features)):\n",
    "            token = features[j][\"token\"]\n",
    "            token_length = count_token_length_special(token)\n",
    "            if char_count == P_char_start:\n",
    "                emb_P += np.asarray(features[j][\"layers\"][0]['values']) \n",
    "            if char_count in range(A_char_start, A_char_start+A_length):\n",
    "                emb_A += np.asarray(features[j][\"layers\"][0]['values'])\n",
    "                cnt_A += 1\n",
    "            if char_count in range(B_char_start, B_char_start+B_length):\n",
    "                emb_B += np.asarray(features[j][\"layers\"][0]['values'])\n",
    "                cnt_B += 1                \n",
    "            char_count += token_length\n",
    "        \n",
    "        emb_A /= cnt_A\n",
    "        emb_B /= cnt_B\n",
    "        \n",
    "        label = \"Neither\"\n",
    "        if (df.loc[i,\"A-coref\"] == True):\n",
    "            label = \"A\"\n",
    "        if (df.loc[i,\"B-coref\"] == True):\n",
    "            label = \"B\"\n",
    "\n",
    "        emb.iloc[i] = [emb_A, emb_B, emb_P, label]\n",
    "        \n",
    "    return emb     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "9d2ca43cace4ee9eeea274df5c57ae5f5db04604"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:66: RuntimeWarning: invalid value encountered in true_divide\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_emb = embed_by_bert(test_df)\n",
    "test_emb.to_json(\"contextual_embeddings_gap_test.json\", orient = 'columns')\n",
    "\n",
    "validation_emb = embed_by_bert(val_df)\n",
    "validation_emb.to_json(\"contextual_embeddings_gap_validation.json\", orient = 'columns')\n",
    "\n",
    "train_emb = embed_by_bert(train_df)\n",
    "train_emb.to_json(\"contextual_embeddings_gap_train.json\", orient = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "72b17716d72fdfe4b9b88ce263b780df1d138a1e"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def bs(lens, target):\n",
    "    low, high = 0, len(lens) - 1\n",
    "\n",
    "    while low < high:\n",
    "        mid = low + int((high - low) / 2)\n",
    "\n",
    "        if target > lens[mid]:\n",
    "            low = mid + 1\n",
    "        elif target < lens[mid]:\n",
    "            high = mid\n",
    "        else:\n",
    "            return mid + 1\n",
    "\n",
    "    return low\n",
    "\n",
    "def b_distance(dist):\n",
    "    \n",
    "    buckets = [1, 2, 3, 4, 5, 8, 16, 32, 64]  \n",
    "    low, high = 0, len(buckets)\n",
    "    while low < high:\n",
    "        mid = low + int((high-low) / 2)\n",
    "        if dist > buckets[mid]:\n",
    "            low = mid + 1\n",
    "        elif dist < buckets[mid]:\n",
    "            high = mid\n",
    "        else:\n",
    "            return mid\n",
    "\n",
    "    return low\n",
    "\n",
    "def distance_features(char_offsetP, char_offsetA, char_offsetB, text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    lens = [token.idx for token in doc]\n",
    "    mention_offsetP = bs(lens, char_offsetP) - 1\n",
    "    mention_offsetA = bs(lens, char_offsetA) - 1\n",
    "    mention_offsetB = bs(lens, char_offsetB) - 1\n",
    "    mention_distA = mention_offsetP - mention_offsetA\n",
    "    mention_distB = mention_offsetP - mention_offsetB\n",
    "    \n",
    "    dist_binA = b_distance(mention_distA)\n",
    "    dist_binB = b_distance(mention_distB)\n",
    "    \n",
    "    return dist_binA, dist_binB\n",
    "\n",
    "def extract_dist_features(df):\n",
    "    \n",
    "    index = df.index\n",
    "    columns = [\"D_PA\", \"D_PB\"]\n",
    "    dist_df = pd.DataFrame(index = index, columns = columns)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        text = df.loc[i, 'Text']\n",
    "        P_offset = df.loc[i,'Pronoun-offset']\n",
    "        A_offset = df.loc[i, 'A-offset']\n",
    "        B_offset = df.loc[i, 'B-offset']   \n",
    "        \n",
    "        dist_df.iloc[i] = distance_features(P_offset, A_offset, B_offset, text)\n",
    "    \n",
    "    return dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "43e7e791ba9fb7fbf4f68abe0a7cfdec52b189a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_dist_df = extract_dist_features(test_df)\n",
    "test_dist_df.to_csv('test_dist_df.csv', index=False)\n",
    "val_dist_df = extract_dist_features(val_df)\n",
    "val_dist_df.to_csv('val_dist_df.csv', index=False)\n",
    "train_dist_df = extract_dist_features(train_df)\n",
    "train_dist_df.to_csv('train_dist_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "65d917c5ca0c0e308cf766f700488fcf183f748c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.models import *\n",
    "\n",
    "class End2End_NCR():\n",
    "    \n",
    "    def __init__(self, word_input_shape, dist_shape, dist_embed_dim=20):\n",
    "        \n",
    "        self.word_input_shape = word_input_shape\n",
    "        self.dist_shape = dist_shape\n",
    "        self.buckets = [1, 2, 3, 4, 5, 8, 16, 32, 64] \n",
    "        self.dist_embed_dim = dist_embed_dim\n",
    "        self.hidden_dim = 120\n",
    "        \n",
    "    def build(self):\n",
    "        \n",
    "        P, A, B = Input((self.word_input_shape,)), Input((self.word_input_shape,)), Input((self.word_input_shape,))\n",
    "        dist_PA, dist_PB = Input((self.dist_shape,)), Input((self.dist_shape,))\n",
    "        \n",
    "        self.dist_embed   = Embedding(len(self.buckets)+1, self.dist_embed_dim)\n",
    "        self.element_wise = Multiply()\n",
    "        self.concat       = Concatenate(axis=-1)\n",
    "        self.flatten      = Flatten()\n",
    "        self.add          = Add()\n",
    "        \n",
    "        dist_PA_embed = self.dist_embed(dist_PA)\n",
    "        dist_PA_embed = self.flatten(dist_PA_embed)\n",
    "        dist_PB_embed = self.dist_embed(dist_PB)\n",
    "        dist_PB_embed = self.flatten(dist_PB_embed)\n",
    "        \n",
    "        #Scoring\n",
    "        score_P = self.FFNN1(P)\n",
    "        score_A = self.FFNN1(A)\n",
    "        score_B = self.FFNN1(B)   \n",
    "        element_wisePA = self.element_wise([P, A])\n",
    "        element_wisePB = self.element_wise([P, B])        \n",
    "        ante_scorePA   = self.FFNN2(self.concat([P, A, element_wisePA, dist_PA_embed]))\n",
    "        ante_scorePB   = self.FFNN2(self.concat([P, B, element_wisePB, dist_PB_embed]))\n",
    "        score_PA = self.add([score_P, score_A, ante_scorePA]) #(batch_size, 1)\n",
    "        score_PB = self.add([score_P, score_B, ante_scorePB]) #(batch_size, 1)\n",
    "        score_e  = Lambda(lambda x: K.zeros_like(x))(score_PB)\n",
    "        \n",
    "        #Final Output\n",
    "        output = self.concat([score_PA, score_PB, score_e])\n",
    "        output = Activation('softmax')(output)\n",
    "        \n",
    "        model = Model([P, A, B, dist_PA, dist_PB], output)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def FFNN1(self, x):\n",
    "        \n",
    "        x = Dense(self.hidden_dim, activation='relu', use_bias=True)(x)\n",
    "        x = Dropout(rate=0.2)(x)\n",
    "        x = Dense(self.hidden_dim, activation='relu', use_bias=True)(x)\n",
    "        x = Dropout(rate=0.2)(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def FFNN2(self, x):\n",
    "        \n",
    "        x = Dense(self.hidden_dim, activation='relu', use_bias=True)(x)\n",
    "        x = Dropout(rate=0.2)(x)\n",
    "        x = Dense(self.hidden_dim, activation='relu', use_bias=True)(x)\n",
    "        x = Dropout(rate=0.2)(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "78ad73eabc65583a927c7f2ac721aa4551ae0992"
   },
   "outputs": [],
   "source": [
    "def create_input(embed_df, dist_df):\n",
    "    \n",
    "    assert len(embed_df) == len(dist_df)\n",
    "    all_P, all_A, all_B = [] ,[] ,[]\n",
    "    all_label = []\n",
    "    all_dist_PA, all_dist_PB = [], []\n",
    "    \n",
    "    for i in tqdm(range(len(embed_df))):\n",
    "        \n",
    "        all_P.append(embed_df.loc[i, \"emb_P\"])\n",
    "        all_A.append(embed_df.loc[i, \"emb_A\"])\n",
    "        all_B.append(embed_df.loc[i, \"emb_B\"])\n",
    "        all_dist_PA.append(dist_df.loc[i, \"D_PA\"])\n",
    "        all_dist_PB.append(dist_df.loc[i, \"D_PB\"])\n",
    "        \n",
    "        label = embed_df.loc[i, \"label\"]\n",
    "        if label == \"A\": \n",
    "            all_label.append(0)\n",
    "        elif label == \"B\": \n",
    "            all_label.append(1)\n",
    "        else: \n",
    "            all_label.append(2)\n",
    "    \n",
    "    return [np.asarray(all_P), np.asarray(all_A), np.asarray(all_B), np.expand_dims(np.asarray(all_dist_PA),axis=1), np.expand_dims(np.asarray(all_dist_PB),axis=1)], all_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "9eecf8cbabf3ebd4e98ba5c80c00b6681a0b4943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=454), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = create_input(train_emb, train_dist_df)\n",
    "X_val, y_val = create_input(validation_emb, val_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "a8868da0032471a11ce42a310978cd7c8342f000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 20)        200         input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 768)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 768)          0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20)           0           embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     multiple             0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 multiply_1[0][0]                 \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 multiply_1[1][0]                 \n",
      "                                                                 flatten_1[1][0]                  \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_1[1][0]                      \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          92280       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          92280       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          279000      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 120)          92280       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 120)          279000      concatenate_1[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 120)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 120)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 120)          0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 120)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 120)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          14520       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 120)          14520       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 120)          14520       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120)          14520       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 120)          14520       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 120)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 120)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 120)          0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 120)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 120)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            121         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            121         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            121         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            121         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            121         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 1)            0           dense_3[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_12[0][0]                   \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "                                                                 dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           add_1[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 3)            0           concatenate_1[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 908,245\n",
      "Trainable params: 908,245\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = End2End_NCR(word_input_shape=X_train[0].shape[1], dist_shape=X_train[3].shape[1]).build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "6d629c89e84284ad426d5c85c3c26499e4c4af6d"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "66129fadd9d8239da3b2661e091f94777b660a5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 454 samples\n",
      "Epoch 1/20\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.8014 - sparse_categorical_accuracy: 0.6650 - val_loss: 0.7846 - val_sparse_categorical_accuracy: 0.6718\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78458, saving model to best_model.hdf5\n",
      "Epoch 2/20\n",
      "2000/2000 [==============================] - 1s 444us/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7125 - val_loss: 0.7659 - val_sparse_categorical_accuracy: 0.6718\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78458 to 0.76593, saving model to best_model.hdf5\n",
      "Epoch 3/20\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.5610 - sparse_categorical_accuracy: 0.7630 - val_loss: 0.7116 - val_sparse_categorical_accuracy: 0.6806\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76593 to 0.71157, saving model to best_model.hdf5\n",
      "Epoch 4/20\n",
      "2000/2000 [==============================] - 1s 441us/step - loss: 0.4604 - sparse_categorical_accuracy: 0.8060 - val_loss: 0.7923 - val_sparse_categorical_accuracy: 0.6674\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.71157\n",
      "Epoch 5/20\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 0.3752 - sparse_categorical_accuracy: 0.8480 - val_loss: 0.7957 - val_sparse_categorical_accuracy: 0.6806\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.71157\n",
      "Epoch 6/20\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.2865 - sparse_categorical_accuracy: 0.8895 - val_loss: 0.8513 - val_sparse_categorical_accuracy: 0.6894\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.71157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3e6d98eba8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Adam(decay=0.0001), loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\n",
    "\n",
    "file_path = \"best_model.hdf5\"\n",
    "check_point = callbacks.ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n",
    "early_stop = callbacks.EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience=3)\n",
    "model.fit(X_train, y_train, batch_size=20, epochs=20, validation_data=(X_val, y_val), \n",
    "                    shuffle=True, callbacks = [check_point, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2dc89fc83e7e2cba124da9ca9b2663e5fbc39fae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = create_input(test_emb, test_dist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "6f16dbf78d029c6840415e69021a242bddfd3695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 91us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>development-1</td>\n",
       "      <td>0.680997</td>\n",
       "      <td>0.247221</td>\n",
       "      <td>0.071782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>development-2</td>\n",
       "      <td>0.879528</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.022433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>development-3</td>\n",
       "      <td>0.038694</td>\n",
       "      <td>0.806677</td>\n",
       "      <td>0.154629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>development-4</td>\n",
       "      <td>0.025057</td>\n",
       "      <td>0.823317</td>\n",
       "      <td>0.151627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development-5</td>\n",
       "      <td>0.202918</td>\n",
       "      <td>0.676270</td>\n",
       "      <td>0.120812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>development-6</td>\n",
       "      <td>0.980097</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.007034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>development-7</td>\n",
       "      <td>0.609203</td>\n",
       "      <td>0.335463</td>\n",
       "      <td>0.055334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>development-8</td>\n",
       "      <td>0.222455</td>\n",
       "      <td>0.625210</td>\n",
       "      <td>0.152335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>development-9</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>0.196064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>development-10</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>0.073344</td>\n",
       "      <td>0.022641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>development-11</td>\n",
       "      <td>0.081087</td>\n",
       "      <td>0.539774</td>\n",
       "      <td>0.379139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>development-12</td>\n",
       "      <td>0.916855</td>\n",
       "      <td>0.059084</td>\n",
       "      <td>0.024061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>development-13</td>\n",
       "      <td>0.564717</td>\n",
       "      <td>0.394353</td>\n",
       "      <td>0.040930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>development-14</td>\n",
       "      <td>0.353678</td>\n",
       "      <td>0.578910</td>\n",
       "      <td>0.067411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>development-15</td>\n",
       "      <td>0.256544</td>\n",
       "      <td>0.486441</td>\n",
       "      <td>0.257014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>development-16</td>\n",
       "      <td>0.153250</td>\n",
       "      <td>0.585169</td>\n",
       "      <td>0.261581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>development-17</td>\n",
       "      <td>0.241399</td>\n",
       "      <td>0.581936</td>\n",
       "      <td>0.176664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>development-18</td>\n",
       "      <td>0.188718</td>\n",
       "      <td>0.751330</td>\n",
       "      <td>0.059951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>development-19</td>\n",
       "      <td>0.027921</td>\n",
       "      <td>0.723171</td>\n",
       "      <td>0.248909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>development-20</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.850492</td>\n",
       "      <td>0.142330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID         A         B   NEITHER\n",
       "0    development-1  0.680997  0.247221  0.071782\n",
       "1    development-2  0.879528  0.098039  0.022433\n",
       "2    development-3  0.038694  0.806677  0.154629\n",
       "3    development-4  0.025057  0.823317  0.151627\n",
       "4    development-5  0.202918  0.676270  0.120812\n",
       "5    development-6  0.980097  0.012869  0.007034\n",
       "6    development-7  0.609203  0.335463  0.055334\n",
       "7    development-8  0.222455  0.625210  0.152335\n",
       "8    development-9  0.021900  0.782036  0.196064\n",
       "9   development-10  0.904015  0.073344  0.022641\n",
       "10  development-11  0.081087  0.539774  0.379139\n",
       "11  development-12  0.916855  0.059084  0.024061\n",
       "12  development-13  0.564717  0.394353  0.040930\n",
       "13  development-14  0.353678  0.578910  0.067411\n",
       "14  development-15  0.256544  0.486441  0.257014\n",
       "15  development-16  0.153250  0.585169  0.261581\n",
       "16  development-17  0.241399  0.581936  0.176664\n",
       "17  development-18  0.188718  0.751330  0.059951\n",
       "18  development-19  0.027921  0.723171  0.248909\n",
       "19  development-20  0.007177  0.850492  0.142330"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"./best_model.hdf5\")\n",
    "y_preds = model.predict(X_test, batch_size = 1024, verbose = 1)\n",
    "\n",
    "sub_df_path = os.path.join('../input/gendered-pronoun-resolution/', 'sample_submission_stage_1.csv')\n",
    "sub_df = pd.read_csv(sub_df_path)\n",
    "sub_df.loc[:, 'A'] = pd.Series(y_preds[:, 0])\n",
    "sub_df.loc[:, 'B'] = pd.Series(y_preds[:, 1])\n",
    "sub_df.loc[:, 'NEITHER'] = pd.Series(y_preds[:, 2])\n",
    "\n",
    "sub_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "6b95c352c3847f2adeaf8153b4eaa46fab958096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6622605040314739"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "y_one_hot = np.zeros((2000, 3))\n",
    "for i in range(len(y_test)):\n",
    "    y_one_hot[i, y_test[i]] = 1\n",
    "log_loss(y_one_hot, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "d17c4e194ecfd465f20b465effe3b7a33038a6dc"
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "bec6b13e27c4219b1a2352177464077d10b7951a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
