{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gendered-pronoun-resolution', 'gap-coreference', 'bert-embedding-e2e-model']\n",
      "['__output__.json', 'contextual_embeddings_gap_validation.json', 'contextual_embeddings_gap_train.json', 'train_dist_df.csv', 'tokenization.py', 'uncased_L-12_H-768_A-12', 'contextual_embeddings_gap_test.json', '__notebook__.ipynb', 'test_dist_df.csv', 'uncased_L-12_H-768_A-12.zip', 'submission.csv', '__results__.html', 'modeling.py', 'custom.css', 'extract_features.py', '__pycache__', 'val_dist_df.csv', 'best_model.hdf5']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "print(os.listdir(\"../input/bert-embedding-e2e-model\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as outp/ut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend, models, layers, initializers, regularizers, constraints, optimizers\n",
    "from keras import callbacks as kc\n",
    "from keras import optimizers as ko\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "import time\n",
    "\n",
    "\n",
    "dense_layer_sizes = [37]\n",
    "dropout_rate = 0.6\n",
    "learning_rate = 0.001\n",
    "n_fold = 5\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "patience = 100\n",
    "# n_test = 100\n",
    "lambd = 0.1 # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "cc89d027ac763f58f4059bd6ac2a4b49c2256e4a"
   },
   "outputs": [],
   "source": [
    "def build_mlp_model(input_shape):\n",
    "\tX_input = layers.Input(input_shape)\n",
    "\n",
    "\t# First dense layer\n",
    "\tX = layers.Dense(dense_layer_sizes[0], name = 'dense0')(X_input)\n",
    "\tX = layers.BatchNormalization(name = 'bn0')(X)\n",
    "\tX = layers.Activation('relu')(X)\n",
    "\tX = layers.Dropout(dropout_rate, seed = 7)(X)\n",
    "\n",
    "\t# Second dense layer\n",
    "# \tX = layers.Dense(dense_layer_sizes[0], name = 'dense1')(X)\n",
    "# \tX = layers.BatchNormalization(name = 'bn1')(X)\n",
    "# \tX = layers.Activation('relu')(X)\n",
    "# \tX = layers.Dropout(dropout_rate, seed = 9)(X)\n",
    "\n",
    "\t# Output layer\n",
    "\tX = layers.Dense(3, name = 'output', kernel_regularizer = regularizers.l2(lambd))(X)\n",
    "\tX = layers.Activation('softmax')(X)\n",
    "\n",
    "\t# Create model\n",
    "\tmodel = models.Model(input = X_input, output = X, name = \"classif_model\")\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "9ad3def6d2a3730a25b0212d740e04e7c64d191b"
   },
   "outputs": [],
   "source": [
    "def parse_json(embeddings):\n",
    "\t'''\n",
    "\tParses the embeddigns given by BERT, and suitably formats them to be passed to the MLP model\n",
    "\n",
    "\tInput: embeddings, a DataFrame containing contextual embeddings from BERT, as well as the labels for the classification problem\n",
    "\tcolumns: \"emb_A\": contextual embedding for the word A\n",
    "\t         \"emb_B\": contextual embedding for the word B\n",
    "\t         \"emb_P\": contextual embedding for the pronoun\n",
    "\t         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n",
    "\n",
    "\tOutput: X, a numpy array containing, for each line in the GAP file, the concatenation of the embeddings of the target words\n",
    "\t        Y, a numpy array containing, for each line in the GAP file, the one-hot encoded answer to the coreference problem\n",
    "\t'''\n",
    "\tembeddings.sort_index(inplace = True) # Sorting the DataFrame, because reading from the json file messed with the order\n",
    "\tX = np.zeros((len(embeddings),3*768))\n",
    "\tY = np.zeros((len(embeddings), 3))\n",
    "\n",
    "\t# Concatenate features\n",
    "\tfor i in range(len(embeddings)):\n",
    "\t\tA = np.array(embeddings.loc[i,\"emb_A\"])\n",
    "\t\tB = np.array(embeddings.loc[i,\"emb_B\"])\n",
    "\t\tP = np.array(embeddings.loc[i,\"emb_P\"])\n",
    "\t\tX[i] = np.concatenate((A,B,P))\n",
    "\n",
    "\t# One-hot encoding for labels\n",
    "\tfor i in range(len(embeddings)):\n",
    "\t\tlabel = embeddings.loc[i,\"label\"]\n",
    "\t\tif label == \"A\":\n",
    "\t\t\tY[i,0] = 1\n",
    "\t\telif label == \"B\":\n",
    "\t\t\tY[i,1] = 1\n",
    "\t\telse:\n",
    "\t\t\tY[i,2] = 1\n",
    "\n",
    "\treturn X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "c10b03cc43cce5636f910154e53277623e6fa816"
   },
   "outputs": [],
   "source": [
    "development = pd.read_json(\"../input/bert-embedding-e2e-model/contextual_embeddings_gap_test.json\")\n",
    "X_development, Y_development = parse_json(development)\n",
    "\n",
    "validation = pd.read_json(\"../input/bert-embedding-e2e-model/contextual_embeddings_gap_validation.json\")\n",
    "X_validation, Y_validation = parse_json(validation)\n",
    "\n",
    "test = pd.read_json(\"../input/bert-embedding-e2e-model/contextual_embeddings_gap_train.json\")\n",
    "X_test, Y_test = parse_json(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "ed0c29bc44c17e08291437dd70bb6a4f264c3795"
   },
   "outputs": [],
   "source": [
    "remove_test = [row for row in range(len(X_test)) if np.sum(np.isnan(X_test[row]))]\n",
    "X_test = np.delete(X_test, remove_test, 0)\n",
    "Y_test = np.delete(Y_test, remove_test, 0)\n",
    "\n",
    "remove_validation = [row for row in range(len(X_validation)) if np.sum(np.isnan(X_validation[row]))]\n",
    "X_validation = np.delete(X_validation, remove_validation, 0)\n",
    "Y_validation = np.delete(Y_validation, remove_validation, 0)\n",
    "\n",
    "# We want predictions for all development rows. So instead of removing rows, make them 0\n",
    "remove_development = [row for row in range(len(X_development)) if np.sum(np.isnan(X_development[row]))]\n",
    "X_development[remove_development] = np.zeros(3*768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e275a4c1b3a2617ce824883494288880ab93e11c"
   },
   "outputs": [],
   "source": [
    "# Will train on data from the gap-test and gap-validation files, in total 2454 rows\n",
    "X_train = np.concatenate((X_test, X_validation), axis = 0)\n",
    "Y_train = np.concatenate((Y_test, Y_validation), axis = 0)\n",
    "\n",
    "# Will predict probabilities for data from the gap-development file; initializing the predictions\n",
    "prediction = np.zeros((len(X_development),3)) # testing predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "9099357198438a14e6f313a7e18c5d77d3c74c3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Mon Mar 18 14:08:05 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 started at Mon Mar 18 14:08:35 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 started at Mon Mar 18 14:09:04 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 started at Mon Mar 18 14:09:36 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 started at Mon Mar 18 14:10:07 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"classif_model\", inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV mean score: 0.5713, std: 0.0258.\n",
      "[0.568871222174138, 0.5388057554337953, 0.6013780037152663, 0.5998513547003944, 0.5477032618459352]\n",
      "Test score: 0.5320507737604062\n"
     ]
    }
   ],
   "source": [
    "# Training and cross-validation\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=3)\n",
    "scores = []\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train)):\n",
    "\t# split training and validation data\n",
    "\tprint('Fold', fold_n, 'started at', time.ctime())\n",
    "\tX_tr, X_val = X_train[train_index], X_train[valid_index]\n",
    "\tY_tr, Y_val = Y_train[train_index], Y_train[valid_index]\n",
    "\n",
    "\t# Define the model, re-initializing for each fold\n",
    "\tclassif_model = build_mlp_model([X_train.shape[1]])\n",
    "\tclassif_model.compile(optimizer = optimizers.Adam(lr = learning_rate), loss = \"categorical_crossentropy\")\n",
    "\tcallbacks = [kc.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights = True)]\n",
    "\n",
    "\t# train the model\n",
    "\tclassif_model.fit(x = X_tr, y = Y_tr, epochs = epochs, batch_size = batch_size, callbacks = callbacks, validation_data = (X_val, Y_val), verbose = 0)\n",
    "\n",
    "\t# make predictions on validation and test data\n",
    "\tpred_valid = classif_model.predict(x = X_val, verbose = 0)\n",
    "\tpred = classif_model.predict(x = X_development, verbose = 0)\n",
    "\n",
    "\t# oof[valid_index] = pred_valid.reshape(-1,)\n",
    "\tscores.append(log_loss(Y_val, pred_valid))\n",
    "\tprediction += pred\n",
    "prediction /= n_fold\n",
    "\n",
    "# Print CV scores, as well as score on the test data\n",
    "print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "print(scores)\n",
    "print(\"Test score:\", log_loss(Y_development,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "e22b5e1b8cb0d66748f7dd598fbaf33d53bae0bf"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/gendered-pronoun-resolution/sample_submission_stage_1.csv\", index_col = \"ID\")\n",
    "submission[\"A\"] = prediction[:,0]\n",
    "submission[\"B\"] = prediction[:,1]\n",
    "submission[\"NEITHER\"] = prediction[:,2]\n",
    "submission.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "befc7e4423830d2e47ca75a4f41e12377319a0b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>NEITHER</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>development-1</th>\n",
       "      <td>0.581317</td>\n",
       "      <td>0.357831</td>\n",
       "      <td>0.060852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-2</th>\n",
       "      <td>0.931677</td>\n",
       "      <td>0.019179</td>\n",
       "      <td>0.049144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-3</th>\n",
       "      <td>0.115164</td>\n",
       "      <td>0.794478</td>\n",
       "      <td>0.090357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-4</th>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.788848</td>\n",
       "      <td>0.173909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-5</th>\n",
       "      <td>0.035224</td>\n",
       "      <td>0.941852</td>\n",
       "      <td>0.022924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-6</th>\n",
       "      <td>0.892007</td>\n",
       "      <td>0.073681</td>\n",
       "      <td>0.034312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-7</th>\n",
       "      <td>0.699387</td>\n",
       "      <td>0.166185</td>\n",
       "      <td>0.134428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-8</th>\n",
       "      <td>0.167732</td>\n",
       "      <td>0.552573</td>\n",
       "      <td>0.279695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-9</th>\n",
       "      <td>0.011870</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.009033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-10</th>\n",
       "      <td>0.649023</td>\n",
       "      <td>0.283964</td>\n",
       "      <td>0.067013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-11</th>\n",
       "      <td>0.117273</td>\n",
       "      <td>0.509603</td>\n",
       "      <td>0.373124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-12</th>\n",
       "      <td>0.908435</td>\n",
       "      <td>0.052392</td>\n",
       "      <td>0.039173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-13</th>\n",
       "      <td>0.584374</td>\n",
       "      <td>0.350982</td>\n",
       "      <td>0.064644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-14</th>\n",
       "      <td>0.622134</td>\n",
       "      <td>0.299796</td>\n",
       "      <td>0.078071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-15</th>\n",
       "      <td>0.419982</td>\n",
       "      <td>0.448202</td>\n",
       "      <td>0.131816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-16</th>\n",
       "      <td>0.457508</td>\n",
       "      <td>0.329977</td>\n",
       "      <td>0.212515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-17</th>\n",
       "      <td>0.187158</td>\n",
       "      <td>0.720008</td>\n",
       "      <td>0.092834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-18</th>\n",
       "      <td>0.631181</td>\n",
       "      <td>0.100784</td>\n",
       "      <td>0.268035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-19</th>\n",
       "      <td>0.102873</td>\n",
       "      <td>0.732786</td>\n",
       "      <td>0.164341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development-20</th>\n",
       "      <td>0.109574</td>\n",
       "      <td>0.765316</td>\n",
       "      <td>0.125111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       A         B   NEITHER\n",
       "ID                                          \n",
       "development-1   0.581317  0.357831  0.060852\n",
       "development-2   0.931677  0.019179  0.049144\n",
       "development-3   0.115164  0.794478  0.090357\n",
       "development-4   0.037243  0.788848  0.173909\n",
       "development-5   0.035224  0.941852  0.022924\n",
       "development-6   0.892007  0.073681  0.034312\n",
       "development-7   0.699387  0.166185  0.134428\n",
       "development-8   0.167732  0.552573  0.279695\n",
       "development-9   0.011870  0.979097  0.009033\n",
       "development-10  0.649023  0.283964  0.067013\n",
       "development-11  0.117273  0.509603  0.373124\n",
       "development-12  0.908435  0.052392  0.039173\n",
       "development-13  0.584374  0.350982  0.064644\n",
       "development-14  0.622134  0.299796  0.078071\n",
       "development-15  0.419982  0.448202  0.131816\n",
       "development-16  0.457508  0.329977  0.212515\n",
       "development-17  0.187158  0.720008  0.092834\n",
       "development-18  0.631181  0.100784  0.268035\n",
       "development-19  0.102873  0.732786  0.164341\n",
       "development-20  0.109574  0.765316  0.125111"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
