{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir('./'))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "import ast\nimport cv2\nfrom keras.utils import to_categorical\nfrom tqdm import tqdm\nimport gc\n\ntrain_simplified = os.path.join('../input', 'train_simplified')\nsample_list = os.listdir(train_simplified)\n\nclass load_img_data(object):\n    \n    def __init__(self):\n        self.size = 64\n        self.train_path = os.path.join('train_df.csv')\n        self.test_path = os.path.join('test_df.csv')\n        \n    def draw_line(self, raw_stroke, lw=6, time_color=True):\n        img = np.zeros((256, 256), np.uint8)\n        for t, stroke in enumerate(raw_stroke):\n            for i in range(len(stroke[0]) - 1):\n                color = 255 - min(t, 10) * 13 if time_color else 255\n                _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n                             (stroke[0][i+1], stroke[1][i+1]), color, lw)\n        img = cv2.resize(img, (self.size, self.size))\n        return img\n    \n    def trainset(self):\n        \n        labels = []\n        all_df = pd.DataFrame()\n        \n        for i, sample_name in enumerate(tqdm(sample_list)):\n            path = os.path.join(train_simplified, sample_name)\n            df = pd.read_csv(path, nrows=30000)\n            all_df = all_df.append(df)\n            labels = labels + len(df) * [i]\n            del df\n        \n        all_df['y']= labels\n        all_df = all_df.sample(frac=1, random_state=0)\n        all_df.to_csv(self.train_path)\n        \n        del all_df\n        del labels\n        \n    def testset(self):\n        \n        labels = []\n        all_df = pd.DataFrame()\n        \n        for i, sample_name in enumerate(tqdm(sample_list)):\n            path = os.path.join(train_simplified, sample_name)\n            df = pd.read_csv(path, skiprows=range(1,30000), header=0, nrows=100)\n            all_df = all_df.append(df)\n            labels = labels + len(df) * [i]\n            del df\n            \n        all_df['y']= labels\n        all_df = all_df.sample(frac=1, random_state=0)\n        all_df.to_csv(self.test_path)\n        \n        del all_df\n        del labels\n\n    def traingen(self):\n        while True:\n            if os.path.exists(self.train_path) == False:\n                self.trainset()\n            for df in pd.read_csv(self.train_path, chunksize=680):\n                x = self.df_to_image_data(df, lw=6)\n                y = to_categorical(df.y, num_classes=len(sample_list))\n                yield x, y\n            \n    def df_to_image_data(self, df, lw=6):\n        df.drawing = df.drawing.apply(ast.literal_eval)\n        x = np.zeros((len(df), self.size, self.size, 1))\n        for i, raw_stroke in enumerate(df.drawing):\n            x[i,:, :, 0] = self.draw_line(raw_stroke, lw=lw)\n        return x\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a17e05571533e108cf67b6d4c3cc3a9dd3bfd0cc"
      },
      "cell_type": "code",
      "source": "load_img_data().testset()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31f9480cc27c8003d2b731c83f91c9f41be4ad48"
      },
      "cell_type": "code",
      "source": "testset = pd.read_csv('test_df.csv')\n\nx_vaild = load_img_data().df_to_image_data(testset, lw=6)\ny_vaild = to_categorical(testset.y, num_classes=len(sample_list))\nprint(x_vaild.shape)\nprint(y_vaild.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "315864e13e9a29e00428e8ecc0cb45bec649534c"
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\nimg = -(x_vaild[32, :, :, 0])/ 2\nlabel = y_vaild[32, :]\nprint(np.argmax(label, 0))\nplt.imshow(img, cmap=plt.cm.gray)\nplt.axis('off')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9dc57b05ce494b667c8b1d874f307c1f0bdc435",
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "from keras import metrics\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom sklearn.model_selection import train_test_split\nfrom keras import optimizers\n\ndef top_3_accuracy(y_true, y_pred):\n    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n    \nmodel = MobileNet(input_shape=(64, 64, 1),  include_top=True, weights=None, classes=340)\nmodel.compile(optimizer= optimizers.Adam(lr=0.002),loss='categorical_crossentropy', \n              metrics=[metrics.categorical_accuracy, top_3_accuracy])\n\ntraingen = load_img_data().traingen()\nhistory = model.fit_generator(traingen, steps_per_epoch=800, epochs=70, verbose=1, \n                              validation_data=(x_vaild, y_vaild))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf4bacd669603ed2090cd17903d476e3e81b86c2"
      },
      "cell_type": "code",
      "source": "def preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6eb73b0dc5bb0095b4a1f1eee0157899ead4bd08",
        "scrolled": false
      },
      "cell_type": "code",
      "source": "test_file = os.path.join('../input', 'test_simplified.csv')\nall_top3 = pd.DataFrame()\n\nfor df in pd.read_csv(test_file, chunksize=1000):\n    test_imgs = load_img_data().df_to_image_data(df, lw=6)\n    test_predictions = model.predict(test_imgs, batch_size=128, verbose=1)\n    top3 = preds2catids(test_predictions)\n    all_top3 = all_top3.append(top3, ignore_index=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9a2d35dc68319c5de5ad7005fcff83c10fa5dc8"
      },
      "cell_type": "code",
      "source": "len(all_top3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9419c4c3961d6a963d8bcda0c4e70658129e85db"
      },
      "cell_type": "code",
      "source": "to_class = {}\nfor i, sample_name in enumerate(sample_list):\n    sample_name= sample_name.replace('.csv', ' ').strip()\n    to_class[i] = sample_name.replace(' ','_')\n\nprint(to_class)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d5fd801d5d20fac4fc77ac295c901fccb73f6b0b"
      },
      "cell_type": "code",
      "source": "all_top3 = all_top3.replace(to_class)\nall_top3.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7c09ebc19d77db286f7c58e3fb701df60bcef6b"
      },
      "cell_type": "code",
      "source": "word = all_top3['a'] + ' ' + all_top3['b'] + ' ' + all_top3['c']\nkey_id = pd.Series()\nfor df in pd.read_csv(test_file, chunksize=680):\n    key_id = key_id.append(df.key_id, ignore_index=True)\nsubmission = pd.DataFrame({'key_id':key_id,\n                          'word':word})\nos.remove('train_df.csv')\nos.remove('test_df.csv')\nprint(submission.head())\nsubmission.to_csv('submission.csv', index=False)\nprint(os.listdir('./'))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}