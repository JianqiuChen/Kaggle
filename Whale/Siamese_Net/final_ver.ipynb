{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir('../'))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['test', 'sample_submission.csv', 'train.csv', 'train']\n['lib', 'working', 'config', 'input']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom itertools import combinations_with_replacement\nimport cv2\nimport numpy.random as rng\n\ndata = pd.read_csv(\"../input/train.csv\")\ncategories = data.groupby('Id').size()\nbatch_size = 32\nbase_size = 105\n\n# Make Categories dictionary\nId_dict = {}\nfor i, id in enumerate(categories.index):\n    if id in Id_dict:\n        continue\n    Id_dict[id] = i\n\ncategories_list = []\nfor k in Id_dict.keys():\n    img_list = data[data.Id == k].Image.values\n    categories_list.append(img_list)\n\ndef read_image(path, image_name, base_size):\n\n    image_path = os.path.join(path, image_name)\n    img = cv2.imread(image_path, 0)\n    img = cv2.resize(img, (base_size, base_size))\n    img = img / 255\n\n    return img\n\ndef select_img(img_list):\n\n    if len(img_list) > 1:\n        choice_index = rng.randint(len(img_list), size=1)\n        choice_img = img_list[choice_index][0]\n    else:\n        choice_img = img_list[0]\n\n    return  choice_img\n\ndef make_batch(batch_size):\n\n    img1 = []\n    img2 = []\n\n    categories = rng.choice(len(Id_dict), size=(batch_size,),replace=False)\n    label = np.zeros(batch_size)\n    label[batch_size//2:] = 1.0\n\n    for i in range(batch_size):\n        category_num = categories[i]\n        img_list = categories_list[category_num]\n        x1 = select_img(img_list)\n\n        if i >= batch_size // 2:\n            dif_num = rng.randint(len(Id_dict), size=1)\n            while dif_num == category_num:\n                dif_num = rng.randint(len(Id_dict), size=1)\n\n            dif_img_list = categories_list[int(dif_num)]\n            x2 = select_img(dif_img_list)\n        else:\n            x2 = select_img(img_list)\n\n        img1.append(x1)\n        img2.append(x2)\n\n    return img1, img2, label\n\ndef generator(batch_size):\n    \n    while True:\n        img1, img2, label = make_batch(batch_size=batch_size)\n        left_input = np.zeros((len(img1), base_size, base_size, 1))\n        right_input = np.zeros((len(img2), base_size, base_size, 1))\n        \n        for i, img_name in enumerate(img1):\n            left_input[i, :, :, 0] = read_image(path='../input/train', image_name=img_name, base_size=base_size)\n        for i, img_name in enumerate(img2):\n            right_input[i, :, :, 0] = read_image(path='../input/train', image_name=img_name, base_size=base_size)\n            \n        yield [left_input, right_input], label\n\nbatch_gen = generator(batch_size=batch_size)",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e073d27bf77adce89f54c3d0ab8d08e4b05a9b8"
      },
      "cell_type": "code",
      "source": "import keras.backend as K\nfrom keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Input, merge, subtract, Lambda\nfrom keras.models import Sequential, Model\nfrom keras.initializers import random_normal\nfrom keras import optimizers\nfrom keras import metrics\nfrom keras import losses\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\nclass Siamese_Net(object):\n\n    def __init__(self, input_shape):\n\n        self.input_shape = input_shape\n        self.initializers_weight = random_normal(mean=0.0, stddev=0.01)\n        self.initializers_bias = random_normal(mean=0.5, stddev=0.01)\n        self.initializers_weight_fully = random_normal(mean=0.0, stddev=0.2)\n\n    def build(self):\n\n        left_input = Input(self.input_shape)\n        right_input = Input(self.input_shape)\n\n        convert = Sequential()\n        convert.add(Conv2D(64, kernel_size=10, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(128, kernel_size=7, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(128, kernel_size=4, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(256, kernel_size=4, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        #the units in the final convolutional layer are flattened into a single vector\n        convert.add(Flatten())\n        #the convolutional layer is followed by a fully connected layer\n        convert.add(Dense(4096, activation='sigmoid', kernel_initializer=self.initializers_weight_fully,\n                          bias_initializer=self.initializers_bias))\n\n        left_features = convert(left_input)\n        right_features = convert(right_input)\n\n        #L1 siamese dist\n        dist = Lambda(lambda x: K.abs(x[0]-x[1]))([left_features, right_features])\n\n        #fully connected + sigmoid\n        out = Dense(1, activation='sigmoid')(dist)\n\n        model = Model(inputs=[left_input, right_input], outputs=out)\n\n        return model",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e590bc3988d25a0eacd5f7cfece9e1be737ef1be",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "model = Siamese_Net(input_shape=(105, 105, 1)).build()\nmodel.summary()\nmodel.compile(optimizer= optimizers.Adam(lr=0.01, decay=0.01),loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])\ncallbacks = [EarlyStopping(patience=1, monitor='loss')]",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 105, 105, 1)  0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 105, 105, 1)  0                                            \n__________________________________________________________________________________________________\nsequential_1 (Sequential)       (None, 4096)         38947648    input_1[0][0]                    \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 4096)         0           sequential_1[1][0]               \n                                                                 sequential_1[2][0]               \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n==================================================================================================\nTotal params: 38,951,745\nTrainable params: 38,951,745\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "72405af53ef3076f3c88d39a5e2367f7ab008e4c"
      },
      "cell_type": "code",
      "source": "def test_generator():\n    \n    choice_num = rng.randint(len(Id_dict), size=1)\n    img_list = categories_list[int(choice_num)]\n    test_img_name = select_img(img_list)\n    \n    #support_category = rng.choice(len(Id_dict), size=(batch_size-1,),replace=False)\n    \n    #while choice_num in support_category:\n        #support_category = rng.choice(len(Id_dict), size=(batch_size-1,),replace=False)\n    \n    support_set = np.zeros((len(Id_dict), base_size, base_size, 1))\n    test_set = np.zeros((len(Id_dict), base_size, base_size, 1))\n    \n    for i in range(len(Id_dict)):\n        test_set[i, :, :, 0] = read_image(path='../input/train', image_name=test_img_name, base_size=base_size)\n        #if i == 0:\n            #support_img_list = img_list\n            #support_img_name = select_img(support_img_list)\n        #else:\n            #support_img_list = categories_list[support_category[i-1]]\n            #support_img_name = select_img(support_img_list)\n        support_img_list = categories_list[i]\n        support_img_name = select_img(support_img_list)\n        support_set[i, :, : , 0] = read_image(path='../input/train', image_name=support_img_name, base_size=base_size)\n        \n    return test_set, support_set, choice_num",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2db0ed235ffa3575d342824b362d8d361120c18f"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm\n\ndef test_one_shot(K):\n    \n    n_correct = 0\n    \n    for i in tqdm(range(K)):\n        test_set, support_set, label = test_generator()\n        prob = model.predict([test_set, support_set])\n        prob = np.squeeze(prob)\n        max_indices = np.argpartition(prob, 5)[:5]\n        for index in max_indices:\n            if index == label:\n                n_correct +=1\n            \n    precision = (n_correct / K) * 100\n    \n    print(\"Got an average of {}% in one-shot learning accuracy\".format(precision))\n    \n    return precision",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "315a2ce90038e124a6a730bc91967904f6ed67af"
      },
      "cell_type": "code",
      "source": "model.fit_generator(batch_gen, verbose=1, epochs=10, steps_per_epoch=200)\nprecision = test_one_shot(K=100)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "595912ca04807375c27ce73cf41193f8c0e50861"
      },
      "cell_type": "code",
      "source": "def predict_generator(predict_img_name):\n    \n    support_set = np.zeros((len(Id_dict), base_size, base_size, 1))\n    predict_set = np.zeros((len(Id_dict), base_size, base_size, 1))\n    \n    for i in range(len(Id_dict)):\n        predict_set[i, :, :, 0] = read_image(path='../input/test', image_name=predict_img_name, base_size=base_size)\n        support_img_list = categories_list[i]\n        support_img_name = select_img(support_img_list)\n        support_set[i, :, : , 0] = read_image(path='../input/train', image_name=support_img_name, base_size=base_size)\n        \n    return predict_set, support_set",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "85ae9a24db0cfde23c4bdd234ea9833f5b1bd1a5"
      },
      "cell_type": "code",
      "source": "def preds2catids(predictions):\n    predictions = np.transpose(predictions)\n    return pd.DataFrame(np.argsort(predictions, axis=1)[:, :5], columns=['a', 'b', 'c', 'd', 'e'])\n\ndef one_shot_predict(test_set):\n    \n    all_top5 = pd.DataFrame()\n    for img in tqdm(test_set):\n        predict_set, support_set= predict_generator(img)\n        prob = model.predict([predict_set, support_set])\n        top5 = preds2catids(prob)\n        all_top5 = all_top5.append(top5, ignore_index=True)\n        \n    return all_top5",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b6b68c724333878b0d14290fbc44281e8e4bef3"
      },
      "cell_type": "code",
      "source": "to_class = {}\nfor key, value in Id_dict.items():\n    to_class[value] = key\n\ntest_set = os.listdir('../input/test')\nall_top5 = one_shot_predict(test_set)\nall_top5 = all_top5.replace(to_class)\nall_top5.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ceddcca1bb856303b4e38aa1ca02abae055bf971"
      },
      "cell_type": "code",
      "source": "predictions = all_top5['a'] + ' ' + all_top5['b'] + ' ' + all_top5['c'] + ' ' + all_top5['d'] + ' ' + all_top5['e'] \n\nsubmission = pd.DataFrame({'Image':test_set,\n                          'Id': predictions})\n\nsubmission.head()\nsubmission.to_csv('submission.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}