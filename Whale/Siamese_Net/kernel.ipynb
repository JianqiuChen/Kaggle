{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir('../'))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['test', 'sample_submission.csv', 'train.csv', 'train']\n['lib', 'working', 'config', 'input']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nfrom itertools import combinations_with_replacement\nfrom PIL import Image\nimport cv2\n\ndata = pd.read_csv(\"../input/train.csv\")\ntrain_data, test_data = train_test_split(data, test_size=0.1, random_state=2018)\ntrain_data.to_csv('../working/train.csv', index=False)\ntest_data.to_csv('../working/test.csv', index=False)\n\ndef preprocess(data):\n\n    img1 = []\n    img2 = []\n    label = []\n\n    imgs = data.Image.values\n    perm = combinations_with_replacement(imgs, 2)\n\n    for p in perm:\n        (x1, x2)= p\n        if (data[data.Image == x1].Id.values == data[data.Image == x2].Id.values): y=1.0\n        else:y=0\n        img1.append(x1)\n        img2.append(x2)\n        label.append(y)\n\n        if len(label) == 5000: break\n\n    return img1, img2, label\n\ndef read_image(path, image_name, base_size):\n    \n    image_path = os.path.join(path, image_name)\n    img = cv2.imread(image_path, 0)\n    img = cv2.resize(img, (base_size, base_size))\n    img = img / 255\n    \n    return img\n\ndef generator(data, batch_size):\n    base_size = 105\n    while True:\n        for df in pd.read_csv(data, chunksize=batch_size):\n            img1, img2, label = preprocess(df)\n            left_input = np.zeros((len(img1), base_size, base_size, 1))\n            right_input = np.zeros((len(img2), base_size, base_size, 1))\n            \n            for i, img_name in enumerate(img1):\n                left_input[i, :, :, 0] = read_image(path='../input/train', image_name=img_name, base_size=base_size)\n            for i, img_name in enumerate(img2):\n                right_input[i, :, :, 0] = read_image(path='../input/train', image_name=img_name, base_size=base_size)\n            \n            yield [left_input, right_input], label\n\ngen = generator(data='../working/train.csv', batch_size=12)\n[left_input, right_input], label = next(gen)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e073d27bf77adce89f54c3d0ab8d08e4b05a9b8"
      },
      "cell_type": "code",
      "source": "import keras.backend as K\nfrom keras.layers import Conv2D, Dense, MaxPool2D, Flatten, Input, merge, subtract, Lambda\nfrom keras.models import Sequential, Model\nfrom keras.initializers import random_normal\nfrom keras import optimizers\nfrom keras import metrics\nfrom keras import losses\n\nclass Siamese_Net(object):\n\n    def __init__(self, input_shape):\n\n        self.input_shape = input_shape\n        self.initializers_weight = random_normal(mean=0.0, stddev=0.01)\n        self.initializers_bias = random_normal(mean=0.5, stddev=0.01)\n        self.initializers_weight_fully = random_normal(mean=0.0, stddev=0.2)\n\n    def build(self):\n\n        left_input = Input(self.input_shape)\n        right_input = Input(self.input_shape)\n\n        convert = Sequential()\n        convert.add(Conv2D(64, kernel_size=10, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(128, kernel_size=7, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(128, kernel_size=4, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        convert.add(MaxPool2D(pool_size=2))\n        convert.add(Conv2D(256, kernel_size=4, strides=(1,1), activation='relu',\n                           kernel_initializer=self.initializers_weight, bias_initializer=self.initializers_bias))\n        #the units in the final convolutional layer are flattened into a single vector\n        convert.add(Flatten())\n        #the convolutional layer is followed by a fully connected layer\n        convert.add(Dense(5005, activation='sigmoid', kernel_initializer=self.initializers_weight_fully,\n                          bias_initializer=self.initializers_bias))\n\n        left_features = convert(left_input)\n        right_features = convert(right_input)\n\n        #L1 siamese dist\n        dist = Lambda(lambda x: K.abs(x[0]-x[1]))([left_features, right_features])\n\n        #fully connected + sigmoid\n        out = Dense(1, activation='sigmoid')(dist)\n\n        model = Model(inputs=[left_input, right_input], outputs=out)\n\n        return model\n\nmodel = Siamese_Net(input_shape=(105, 105, 1)).build()\nmodel.summary()",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_9 (InputLayer)            (None, 105, 105, 1)  0                                            \n__________________________________________________________________________________________________\ninput_10 (InputLayer)           (None, 105, 105, 1)  0                                            \n__________________________________________________________________________________________________\nsequential_5 (Sequential)       (None, 5005)         47325901    input_9[0][0]                    \n                                                                 input_10[0][0]                   \n__________________________________________________________________________________________________\nlambda_4 (Lambda)               (None, 5005)         0           sequential_5[1][0]               \n                                                                 sequential_5[2][0]               \n__________________________________________________________________________________________________\ndense_9 (Dense)                 (None, 1)            5006        lambda_4[0][0]                   \n==================================================================================================\nTotal params: 47,330,907\nTrainable params: 47,330,907\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e590bc3988d25a0eacd5f7cfece9e1be737ef1be"
      },
      "cell_type": "code",
      "source": "model.compile(optimizer= optimizers.Adam(lr=0.001),loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy])",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "915052f38e35162b595ef981731127328e2dd322"
      },
      "cell_type": "code",
      "source": "model.fit_generator(gen, epochs=100, verbose=1, steps_per_epoch=len())",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch 1/10\n10/10 [==============================] - 14s 1s/step - loss: 0.6793 - binary_accuracy: 0.5756 - binary_crossentropy: 0.6793\nEpoch 2/10\n10/10 [==============================] - 9s 911ms/step - loss: 0.6300 - binary_accuracy: 0.7449 - binary_crossentropy: 0.6300\nEpoch 3/10\n10/10 [==============================] - 10s 1s/step - loss: 0.6232 - binary_accuracy: 0.7513 - binary_crossentropy: 0.6232\nEpoch 4/10\n10/10 [==============================] - 10s 1s/step - loss: 0.6358 - binary_accuracy: 0.6564 - binary_crossentropy: 0.6358\nEpoch 5/10\n10/10 [==============================] - 10s 984ms/step - loss: 0.5160 - binary_accuracy: 0.7769 - binary_crossentropy: 0.5160\nEpoch 6/10\n10/10 [==============================] - 11s 1s/step - loss: 0.4591 - binary_accuracy: 0.7487 - binary_crossentropy: 0.4591\nEpoch 7/10\n10/10 [==============================] - 10s 1s/step - loss: 0.5133 - binary_accuracy: 0.7077 - binary_crossentropy: 0.5133\nEpoch 8/10\n10/10 [==============================] - 10s 1s/step - loss: 0.5065 - binary_accuracy: 0.7423 - binary_crossentropy: 0.5065\nEpoch 9/10\n10/10 [==============================] - 10s 1s/step - loss: 0.5605 - binary_accuracy: 0.6846 - binary_crossentropy: 0.5605\nEpoch 10/10\n10/10 [==============================] - 10s 1s/step - loss: 0.4711 - binary_accuracy: 0.7372 - binary_crossentropy: 0.4711\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fa9e45c3c50>"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}